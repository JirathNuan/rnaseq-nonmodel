[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Transcriptome Data Analysis in Non-model Organisms",
    "section": "",
    "text": "Preface\nWelcome to the book of Transcriptome Data Analysis in Non-Model Organisms.\n\n\n\nA confusion matrix\n\n\nWe‚Äôll update this page ASAP!"
  },
  {
    "objectID": "01_intro_mobaxterm.html#mobaxterm-for-windows",
    "href": "01_intro_mobaxterm.html#mobaxterm-for-windows",
    "title": "1¬† Introduction to MobaXterm, Terminal, and SSH",
    "section": "1.1 MobaXterm (for Windows)",
    "text": "1.1 MobaXterm (for Windows)\nMobaXterm is a toolbox for remote computing. In a single Windows application, it provides loads of functions that are tailored for programmers, webmasters, IT administrators and pretty much all users who need to handle their remote jobs in a more simple fashion. MobaXterm provides all the important remote network tools, such as SSH, X11, RDP, VNC, FTP, MOSH, and of course, Unix commands, and many more!\n\n\n\nMobaXterm user interface. In the context of remote access through SSH and FTP, mobaXterm provides easy-to-access route as (1) a secure shell (SSH) terminal of the remote server, (2) a list of remote server you‚Äôve accessed, (3) Utilities facilitating remote server access including entertainment, like Swiss army knife!, (4) If you want to reduce redundant typing, just set macro to it, and (5) a files available in the current working directory in the remote server, you can also transfer files from remote server to your local computer using this route!\n\n\nThere are many advantages of having an All-In-One network application for your remote tasks, e.g.¬†when you use SSH to connect to a remote server, a graphical SFTP browser will automatically pop up in order to directly edit your remote files.\nVisit MobaXterm official website to see a demo: https://mobaxterm.mobatek.net/demo.html"
  },
  {
    "objectID": "01_intro_mobaxterm.html#terminal-for-macos",
    "href": "01_intro_mobaxterm.html#terminal-for-macos",
    "title": "1¬† Introduction to MobaXterm, Terminal, and SSH",
    "section": "1.2 Terminal (for macOS)",
    "text": "1.2 Terminal (for macOS)\nTerminal provides a command-line interface to macOS. Each window in Terminal represents an instance of a shell process. The window contains a prompt that indicates you can enter a command. The prompt you see depends on your Terminal and shell settings, but it often includes the name of the host you‚Äôre logged in to, your current working folder, your user name, and a prompt symbol. For example, if a user named michael is using the default zsh shell, the prompt appears as:\nmichael@MacBook-Pro ~ %\nThis indicates that the user named michael is logged in to a computer named MacBook-Pro, and the current folder is his home folder, indicated by the tilde (~).\nMacOS features a built-in SSH client called Terminal which allows you to quickly and easily connect to a server. Starting from open the ‚Äúterminal‚Äù app, and enter the standard SSH command:\nssh user@IPAddress\nThis will connect to the server via SSH with the username `user` and the default SSH port 22. The connection will look similar to the following:"
  },
  {
    "objectID": "01_intro_mobaxterm.html#connecting-to-remote-server",
    "href": "01_intro_mobaxterm.html#connecting-to-remote-server",
    "title": "1¬† Introduction to MobaXterm, Terminal, and SSH",
    "section": "1.3 Connecting to Remote Server",
    "text": "1.3 Connecting to Remote Server\nBioinformatics data processing tasks require more computing power than our laptops, so we need large servers or clusters. It‚Äôs likely you‚Äôll work mostly over a network connection with remote machines on some projects. It can be frustrating for beginners to work with a remote machine. So, This part will introduce you to some commonly used bash commands. To make it easier for beginners to manage their remote machines, there are a range of different tools and technologies available, such as SSH, FTP, and terminal commands, which can be used to access and manage the environment of the machine. Additionally, there are a variety of bash commands which can be used to streamline the process of managing the machine.\nWhat you need to know for connecting to a remove server:\n\nYour username and password in the remote server\nIP address of the remote server, and which port to connect to server\nYou should know whether the remote server accessible via local network or a public IP address\n\nBy default, SSH uses port 22 but it can be changed to a non-standard port. To securely connect the client to the remote server, SSH uses symmetric encryption, asymmetric encryption, and hashing. If you‚Äôre connecting for the first time, you‚Äôll be asked to verify the server‚Äôs public key. Whenever you connect to the same server in the future, the client will reference this verified public key. During an SSH connection, the client and server negotiate a session key used to encrypt and decrypt data.\n\n\n\nIn order to establish a connection, SSH needs to verify SHA keys once connected for the first time. Once authentication is complete, the SSH connection is secure and can be trusted for future access.\n\n\nUpon connecting to the remote server, you‚Äôll see a welcome message like this\n\n\n\nAn example welcome message of server using Ubuntu, including general software and hardware status, information of the latest connection, as well as a prompt for user command."
  },
  {
    "objectID": "02_basic_bash.html#linux-file-systems",
    "href": "02_basic_bash.html#linux-file-systems",
    "title": "2¬† Bash Command Language for Biologists",
    "section": "2.1 Linux File Systems",
    "text": "2.1 Linux File Systems\nIn Unix-like operating systems, the Linux file system defines the directory structure and contents. Even if they‚Äôre located on different physical or virtual hard disks, all files and directories are located under the root directory.\n\n\n\nSchematic hierarchy of Linux file systems. The figure is adopted from https://www.geeksforgeeks.org/linux-file-hierarchy-structure.\n\n\n\nRoot (/)\n\nIt is the root directory of the entire file system hierarchy and the primary hierarchy root. The root directory is where everything begins. This directory can be written only by root.\n\n/bin\n\nEssential commands that must be available with all users, for example, cat, ls, cp, cd, top, mkdir and many more.\n\n/dev\n\nEssential device files such as /dev/null, /dev/shm. This includes terminal devices, USB or other devices connected to the system.\n\n/etc\n\nSystem-wide configuration files for the host, contain files that all programs need. Also included are startup and shutdown shell scripts for starting and stopping individual programs, such as /etc/fstab for permanently mounting external disks, /etc/netplan for configuring the network and IP address, and more.\n\n/home\n\nUsers‚Äô home directories, where they keep their saved files and settings. These directories are used to store all of a user‚Äôs files and settings in one place so that they can easily access their data and keep it organized. For example /home/ponsit, /home/jiratchaya, /home/prasert.\n\n/lib\n\nContain essential libraries for the binaries in /bin/ and /sbin/.\n\n/media\n\nMount points for removable media such as CD-ROMs (deprecated).\n\n/mnt\n\nTemporary mount directory where sysadmins can mount file systems, such as /mnt/external_disk_1, /mnt/removable_drive_1, etc.\n\n/opt\n\nOptional application software packages, including add-on applications from individual vendors.\n\n/sbin\n\nEssential system binaries, e.g., fsck, init, route.\n\n/tmp\n\nTemporary files that aren‚Äôt preserved between reboots and may be severely restricted.\n\n/usr\n\nA secondary hierarchy for read-only user data. Most utilities and applications are located here."
  },
  {
    "objectID": "02_basic_bash.html#basic-bash-commands",
    "href": "02_basic_bash.html#basic-bash-commands",
    "title": "2¬† Bash Command Language for Biologists",
    "section": "2.2 Basic Bash Commands",
    "text": "2.2 Basic Bash Commands\nBash is a Unix shell that allows you to enter commands that are then interpreted and executed by the computer. Commands can be used to perform tasks such as creating a directory, running a program, or deleting a file. Bash is a type of interpreter that takes user input and converts it into a language that the computer can understand and execute. Commands usually consist of keywords, arguments, and flags that allow the user to control how the command is interpreted and executed by the computer.\n\nCreating directories\nKeeping all your files in a single directory makes things much easier for you and your collaborators, and makes it easier to reproduce. Suppose you‚Äôre working on a transcriptome analysis of Cyanophora paradoxa. Your first step would be to choose a short, appropriate project name and create some basic directories.\n\nüóíÔ∏èNote: In Linux file system, directory is exactly the same with folder.\n\nTo keep it short and clear, ‚ÄòCpa‚Äô is used as an alias article name for C. paradoxa, and as the name of the directory, followed by words describing your work, for example.\n\n‚ö†Ô∏è warning: Avoid using spaces ( ) or special characters such as slashes ( / ), backslashes ( \\ ), accented characters ( ‚Äô ), tilde ( ~ ), and many others. It is recommended to use underscore ( _ ) or hyphen ( - ) instead of these special characters.\n\n\nCreate a directory name ‚ÄòCpa_RNASeq‚Äô from current working directory\n\nmkdir Cpa_RNASeq\nThis will create a directory named ‚ÄòCpa_RNASeq‚Äô in your current working directory. Let us create some subdirectories!\n\nCreate subdirectory ‚Äò01_Rawdata‚Äô under the ‚ÄòCpa_RNASeq‚Äô directory\n\nmkdir Cpa_RNASeq/01_Rawdata\nThis will create a subdirectory name ‚Äò01_Rawdata‚Äô in the directory ‚ÄòCpa_RNASeq‚Äô\n\nCreate multiple directory at once\n\nFor example, if you want to create 2 directories named ‚Äò02_QC‚Äô and ‚Äò03_assembly‚Äô under the ‚ÄòCpa_RNASeq‚Äô directory, then simply type\nmkdir Cpa_RNASeq/{02_QC,03_assembly}\n\n\n\n\n\n\nActivity\n\n\n\nA well-organized project directory can make life easier. Your project directory should be organized in a consistent and understandable way. A clear project organization makes it easier for both you and your collaborators to find out exactly where and what everything is located, which improves the reproducibility of research. It‚Äôs also much easier to automate tasks when files are organized and clearly named.\nIn this workshop, we‚Äôll learn transcriptome data analysis in many steps from downloading reads to transcriptome annotation. Therefore, we‚Äôll divide each analysis step into subdirectories as follows. Let‚Äôs assume that we have already created the directory Cpa_RNASeq.\n.\n‚îî‚îÄ‚îÄ Cpa_RNASeq\n    ‚îú‚îÄ‚îÄ 01_Rawdata\n    ‚îú‚îÄ‚îÄ 02_QC\n    ‚îú‚îÄ‚îÄ 03_assembly\n    ‚îú‚îÄ‚îÄ 04_DE_analysis\n    ‚îî‚îÄ‚îÄ 05_annotation\nCould you generate bash command(s) to create these directories ?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nmkdir Cpa_RNASeq/{01_Rawdata,02_QC,03_assembly,04_DE_analysis,05_annotation}\nor\nmkdir Cpa_RNASeq/01_Rawdata Cpa_RNASeq/02_QC Cpa_RNASeq/03_assembly Cpa_RNASeq/04_DE_analysis Cpa_RNASeq/05_annotation\nor\ncd Cpa_RNASeq\nmkdir 01_Rawdata 02_QC 03_assembly 04_DE_analysis 05_annotation\n\n\n\n\n\nNavigating your file system\nThe file system manages the files and directories of the operating system. It organizes our data into files, which store information, and directories. When you see the prompt below on your terminal‚Äôs screen, it means that your terminal has processed the command you entered and is ready for the next command.\njiratchaya@DESKTOP-P2DD13C:~$\njiratchaya is username using this terminal. The address @ symbol followed by DESKTOP-P2DD13C in a computer or server name. And, the dollar sign $ is a prompt, which shows us that the shell is waiting for input. Your shell may use a different character as a prompt and may add information before the prompt.\nIf you want to find out where we are now, type\npwd\npwd stands for print working directory. Without explicit specification, the computer assumes that we want to execute commands in our current working directory. This can be a user‚Äôs home directory (~).\nIf you want to change the directory, e.g.¬†to the ‚ÄòCpa_RNASeq‚Äô directory we just created, just type the following\ncd Cpa_RNASeq\ncd stands for ‚Äúchange directory‚Äù. You can change our working directory by typing cd followed by a directory name. In this case you change from the current directory to the directory named ‚ÄòCpa_RNASeq‚Äô.\n\n\nListing directories\nWe can see what files and subdirectories are in this directory by running ls, which stands for ‚Äúlisting‚Äù:\nls\nExpected result:\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ ls\n01_Rawdata  02_QC  03_assembly\nLet us look at the other way. This way is to list all the files and directories, including the users who own them, the permissions, and the file size in bytes.\nls -l\nExpected result:\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ ls -l\ntotal 12\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 01_Rawdata\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 02_QC\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 03_assembly\nList files and folders, permissions and size in a human readable format.\nls -lh\nExpected result:\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ ls -l\ntotal 12\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 01_Rawdata\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 02_QC\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 03_assembly\nSee all hidden files and directories\nls -la\nExpected result:\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ ls -la\ntotal 20\ndrwxr-xr-x 5 jiratchaya jiratchaya 4096 Mar  1 21:02 .\ndrwxr-x--- 3 jiratchaya jiratchaya 4096 Mar  1 21:02 ..\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 01_Rawdata\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 02_QC\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:02 03_assembly\n\n\nFiles and directories handling\n\nCreating and editing files\nWhen you work on the command line, you often need to create or edit text files. In this workshop, we recommend using nano as a text editor. Other Unix text editors you may have heard of include vi, vim, emacs, vscode, and many more.\nWe‚Äôll create the file test.fasta. To open an existing file or create a new file, type nano followed by the filename:\nnano test.fasta\nThis will bring up the text editing screen on your terminal. Here you can type anything you want, but in this case we‚Äôll create a sequence like this.\n>seq_01\nTCGCTAGTC\n\n>seq_02\nTAGCGAGTT\n\nüóíÔ∏èNote:Always leave an enter in the last line. This is advantageous if this file is further used by many programmes.\n\n\n\n\nThe text editing screen is displayed once you have typed nano into some files. At the bottom of the window is a list of the most important keyboard shortcuts for the nano editor. All commands are preceded by either a ^ or an M character. The caret symbol (^) stands for the Ctrl key. For example, the commands ^J mean that you press the Ctrl and J keys simultaneously. The letter M stands for the Alt key.\n\n\nTo edit a file, you can use the navigation keys such as arrow keys, End, Home, PgUp or PgDn to control the cursor.\nTo save the changes you made to the file, press Ctrl+o. If the file doesn‚Äôt exist yet, it‚Äôll be created after saving.\nTo exit nano, press Ctrl+x. If there are unsaved changes, you‚Äôll be asked if you want to save the changes. Nano will ask you ‚ÄòSave modified buffer?‚Äô, then type y to confirm the edit.\n\n\nCopying files and directories\nTo copy files and directories the command cp can be used. cp stands for copy and is used to copy files and directories in Linux. An example: You copy the file test.fasta to 01_Rawdata with the following syntax\ncp [source file] [target_directory]/\nFor example\ncp test.fasta 01_Rawdata/\nCopy file to another file, using the syntax\ncp [source_file] [new_file_name]\nFor example\ncp test.fasta test_2.fasta\nYou can copy a file to a new file in the directory by using the following syntax\ncp [source_file] [target_directory]/[new_file_name]\nFor example\ncp test.fasta 01_Rawdata/another_test.fasta\nTo copying directory, use additional flag as follow\ncp -r [source_directory] [new_directory_name]\nThe flag -r stands for recursive, i.e.¬†all files and subdirectories in this directory are copied repeatedly. For example, 01_Rawdata already contains test.fasta, which we copied before, and we want to duplicate this directory.\ncp -r 01_Rawdata/ 01_Rawdata_new\n\n\nMoving files and directories\nTo copy files and directories, the command mv can be used. mv stands for move and is used to move files and directories in Linux. For example, move the file test_2.fasta to the directory 01_Rawdata_new with the following syntax\nmv [file_to_move] [target_directory]\nmv test_2.fasta 01_Rawdata_new/\nSpecifically, to move files and directories, no flags are required as with cp. So if we want to move 01_Rawdata_new to a subdirectory of 01_Rawdata, this can be done as follows\nmv [source_file_or_dir] [target_file_or_dir]\nmv 01_Rawdata_new/ 01_Rawdata\nMoving file within the directory up to the current directory\nmv [source_dir]/[source_file] .\nThe dot ( . ) stands for the current directory, which means you want to move something to the current directory. For example, we want to move the file another_test.fasta, which is in the directory 01_Rawdata, to the current directory by typing\nmv 01_Rawdata/another_test.fasta .\n\n\nDeleting files and directories\nRemoving files and directories can be done with the command rm. rm stands for remove and is used to delete files and directories in Linux. It‚Äôs simple and straightforward with the following syntax.\nrm [file_to_delete]\nFor example, you are deleting file another_test.fasta\nrm another_test.fasta\nTo delete directories, use additional flags\nrm -rf [directory_to_delete]\nThe flag -r means that it does something recursive, which means that it deletes all files and subdirectories of the directory you want to delete. The flag f can help us delete some protected files and directories that you should think twice before deleting.\nFor example you want to delete 03_adapter_trimming directory\nrm -rf 03_adapter_trimming\nOr delete subdirectory 01_Rawdata_new by\nrm -rf 01_Rawdata/01_Rawdata_new\nDon‚Äôt worry~ the 01_Rawdata is still with us\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ ls -l\ntotal 20\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 22:33 01_Rawdata\ndrwxr-xr-x 2 jiratchaya jiratchaya 4096 Mar  1 21:59 02_QC\n-rw-r--r-- 1 jiratchaya jiratchaya   38 Mar  1 22:00 another_test.fasta\n-rw-r--r-- 1 jiratchaya jiratchaya   38 Mar  1 21:59 test.fasta\n-rw-r--r-- 1 jiratchaya jiratchaya   38 Mar  1 22:00 test_2.fasta\n\nüö® Danger zone: Be sure to check the path of the location where you want to delete something with the command rm -rf, otherwise you‚Äôll unintentionally delete necessary files or directories.\n\n\n\n\n\n\n\n\n\nDownloading file from URL\nThere are numerous ways to download a file from a URL via the command line on Linux, and two of the best tools for this task are wget and curl. Both tools have their advantages and disadvantages, depending on the download task at hand. However, in this workshop we‚Äôll mainly focus on downloading with curl.\nFor example, we want to download the latest (draft) genome assembly report of Cyanophora paradoxa from the NCBI genome database via curl as follows.\ncurl -O https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/004/431/415/GCA_004431415.1_ASM443141v1/GCA_004431415.1_ASM443141v1_assembly_report.txt\nExpected output\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ curl -O https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/004/431/415/GCA_004431415.1_ASM443141v1/GCA_004431415.1_ASM443141v1_assembly_report.txt\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 61357  100 61357    0     0  21604      0  0:00:02  0:00:02 --:--:-- 21604\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ ls -l\ntotal 80\ndrwxr-xr-x 2 jiratchaya jiratchaya  4096 Mar  1 22:33 01_Rawdata\ndrwxr-xr-x 2 jiratchaya jiratchaya  4096 Mar  1 21:59 02_QC\n-rw-r--r-- 1 jiratchaya jiratchaya 61357 Mar  1 22:56 GCA_004431415.1_ASM443141v1_assembly_report.txt\n-rw-r--r-- 1 jiratchaya jiratchaya    38 Mar  1 22:00 another_test.fasta\n-rw-r--r-- 1 jiratchaya jiratchaya    38 Mar  1 21:59 test.fasta\n-rw-r--r-- 1 jiratchaya jiratchaya    38 Mar  1 22:00 test_2.fasta\nTips: The alternative way to retrieve genome information from NCBI, you can just go to NCBI Genome Data Hub and specify species name to get information. NCBI provides several routes to download files including curl!\n\n\n\nA genome assembly of C. paradoxa in NCBI genome data hub (Accessed: 1 March 2023)\n\n\n\n\nInspecting file\nWe‚Äôll inspect the assembly report file GCA_004431415.1_ASM443141v1_assembly_report.txt that we just downloaded from NCBI\n\nCount how many lines in that file\n\nwc -l GCA_004431415.1_ASM443141v1_assembly_report.txt\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ wc -l GCA_004431415.1_ASM443141v1_assembly_report.txt\n743 GCA_004431415.1_ASM443141v1_assembly_report.txt\n\nPrint some contents at a time.\n\nNow you will see the number of lines that fit on your screen, and you can scroll up and down with the arrow keys. Then press q when you have checked your file.\nless GCA_004431415.1_ASM443141v1_assembly_report.txt\n\n\n\nExample of inspecting a file with the less command. Users can scroll up and down with the arrow keys and exit by pressing q.\n\n\n\nPrint top 10 lines of file\n\nhead GCA_004431415.1_ASM443141v1_assembly_report.txt\n\n\n\nThe first 10 lines of C. paradoxa assembly report file\n\n\n\nPrint bottom 10 lines of file\n\ntail GCA_004431415.1_ASM443141v1_assembly_report.txt\n\n\n\nThe last 10 lines of C. paradoxa assembly report file.\n\n\n\nPrint only lines with a specific pattern of word.\n\nFor example, we‚Äôll print only the lines contain the word ‚ÄúChloroplast‚Äù\ngrep \"Chloroplast\" GCA_004431415.1_ASM443141v1_assembly_report.txt\n\n\n\nExtracted lines with a specific word ‚ÄúChloroplast‚Äù in assembly report file.\n\n\n\n\nShow latest commands we used\nYou can simply press arrow keys up or down to see your latest commands that you typed in the terminal.\nAnother way to see the latest command by typing below in the terminal\nhistory\nHistory is able to keep track of the command lines you use, associate any data with each line, and use information from previous lines when writing new lines.\n\n\nShortcut: Tab Completion\nWhen typing file or directory names, it‚Äôs easy to mistype. Instead, we can use ‚Äòtab‚Äô to complete what we want to type. The shell will try to fill in the rest of a directory or file name if you press tab after typing.\n\n\n\nUsing tab autocomplete in bash.\n\n\n\n\n2.2.1 Have no idea what this command can do\nBasically, the built-in Linux system commands store usage in their command manual. You can call man followed by a command you want to learn more about. for example man curl.\n\n\n\nA manual page of curl. Users can scroll using arrow keys up and down, and quit reading by press q."
  },
  {
    "objectID": "02_basic_bash.html#maintaining-long-running-jobs-with-tmux",
    "href": "02_basic_bash.html#maintaining-long-running-jobs-with-tmux",
    "title": "2¬† Bash Command Language for Biologists",
    "section": "2.3 Maintaining Long-Running Jobs with tmux",
    "text": "2.3 Maintaining Long-Running Jobs with tmux\nWhen we run programs through the Unix shell, they run until they terminate successfully or are terminated with an error. Multiple processes running simultaneously on your computer, such as system files, web browser, email application, bioinformatics programs, and so on. In bioinformatics, we often work with processes that run for a long period of time. Therefore, it‚Äôs important that we know how to work with processes and manage them using the Unix shell. In this section, we‚Äôll learn the basics of dealing with processes.\nIn addition, processes are also terminated if the connection to the servers is interrupted, the network connection drops immediately, or the power fails. Since we‚Äôre constantly working with remote computers in our daily work in bioinformatics, we need a way to prevent the accidental termination of long-running applications. Leaving the local terminal‚Äôs connection to a remote computer open while a program is running is an unsafe solution, even the most reliable networks can experience short outages.\n\n\n\nHow tmux increase you pruductivity :/\n\n\nSome software offers the user the possibility to run their work as a background process, e.g.¬†Nohup, Screen and Tmux. In this workshop, we propose Terminal Multiplexer (Tmux), which allows you to create a session with multiple windows, each of which can run its own processes. The Tmux sessions are persistent, which means that all the windows and their processes can be easily restored by reattaching the session.\nWhen Tmux is running on a remote machine, you can maintain a persistent session that isn‚Äôt lost when the connection drops or you close your terminal window to go home (or even exit your terminal programme). Rather, all Tmux sessions can be reattached to the terminal you‚Äôre currently at - simply log back into the remote machine via SSH and reattach the Tmux session. All windows remain undisturbed and all processes continue to run.\n\nA simple usage of Tmux\nOpen a terminal and use the following command\ntmux\nYou see a command prompt as usual, but you now see a taskbar-style menu at the bottom of the terminal that contains something like bash 0 *. The asterisk indicates that this is your active window.\n\n\n\nTmux windows\n\n\n\n\nDetach a session\nThis allows you to leave the tmux session, but it continues to run in the background. Just press the key\n[ctrl + b] + d\nYour terminal will print\njiratchaya@DESKTOP-P2DD13C:~/Cpa_RNASeq$ tmux\n[detached (from session 0)]\nThis should take you back to a standard prompt. Remember that the Tmux session continues in the background, and you can recall it at any time.\n\n\nName the Tmux session\nYou may find it helpful to name your sessions with meaningful titles to keep things organized. Let‚Äôs try naming your first session with Tmux.\nYou can name it anything that we want, but in this case I will name it ‚Äòprocess2‚Äô. Enter the following command:\ntmux new -s process2\nYou should now have a new Tmux session running. If you look in the lower left area of the window, you will see the name of your session rather than the generic ‚Äòbash‚Äô.\n\n\nList tmux sessions\nWhat happened to your session? It is still running in the background. You can reopen the session by name or number ID, but what if you forgot the session name?\nThere is a list function built into tmux:\ntmux ls\nThis lists all your current tmux sessions. When you run it, you get output like this:\n\n\n\nList of running tmux sessions.\n\n\n\n\nReenter (aka reattach) a session in Tmux\nTo reopen your tmux session, you can use the tmux command with the attach or attach-session option as follows:\ntmux a -t [session_name]\nFor example, we‚Äôll reenter to the process2 session.\ntmux a -t process2\n\n\nExit tmux when finish running\nQuitting tmux is exactly the same as quitting the standard terminal by pressing the keys Ctrl+d or by entering\nexit"
  },
  {
    "objectID": "02_basic_bash.html#resources",
    "href": "02_basic_bash.html#resources",
    "title": "2¬† Bash Command Language for Biologists",
    "section": "2.4 Resources",
    "text": "2.4 Resources\n\nBuffalo, V. (2015). Bioinformatics data skills: Reproducible and robust research with open source tools. ‚Äù O‚ÄôReilly Media, Inc.‚Äù.\nIntroduction to the command line interface by Harvard Chan Bioinformatics Core (Accessed on 27 Feb 2023).\nIntroducing the Shell, from the course Introduction to the Command Line for Genomics in bioinformatics-core-shared-training (Accessed on 28 Feb 2023)\nBash cheat sheet from RehanSaeed GitHub repository (Accessed on 1 March 2023).\nGetting Started with Tmux [Beginner‚Äôs Guide]. By linuxhandbook.com (Accessed on 2 March 2023)"
  },
  {
    "objectID": "03_sra.html#what-is-sequence-read-archives-sra",
    "href": "03_sra.html#what-is-sequence-read-archives-sra",
    "title": "3¬† Data Retrieval with NCBI SRA Toolkit",
    "section": "3.1 What is Sequence Read Archives (SRA)",
    "text": "3.1 What is Sequence Read Archives (SRA)\nThe Sequence Read Archive (SRA) is the largest publicly accessible repository for high-throughput sequencing data. SRA accepts data from all areas of sequencing projects as well as metagenomics and environmental studies. Sequencing data may be isolated from a single species or from multiple species as in metagnomics studies.\nSRA also refers in the file description to the format defined by NCBI for NGS data in the SRA database. All data submitted to NCBI must be stored in SRA format and can be converted back to a FASTQ, FASTA, or BAM file depending on the original submission by the researchers. Here, the SRA Toolkit provides tools for downloading data, converting various data formats to SRA format and vice versa, and extracting SRA data to other formats.\nResearchers often use SRA data to make discoveries and conduct reproducible research. Data sets can be compared using the SRA web interface. However, if you want to download files for local use on your computer, you should use a command line interface, and the SRA Toolkit is highly recommended by NCBI."
  },
  {
    "objectID": "03_sra.html#searching-rna-sequencing-datasets-in-ncbi",
    "href": "03_sra.html#searching-rna-sequencing-datasets-in-ncbi",
    "title": "3¬† Data Retrieval with NCBI SRA Toolkit",
    "section": "3.2 Searching RNA-Sequencing datasets in NCBI",
    "text": "3.2 Searching RNA-Sequencing datasets in NCBI\nThe databases in NCBI are linked by some common features. This means that you can start wherever you have your research problems in NCBI. In this workshop, we will investigate transcriptional changes during light exposure of the alga Cyanophora paradoxa, a representative species of Glaucophytes. For more information about this alga, please see this article in Science.\n\n\n\n\n\n\nActivity\n\n\n\nYou can easily search the SRA database for any keywords of interest related to your research. In this context, we search for all SRA studies related to C. paradoxa and see what SRA provides us. Note that the SRA database contains not only transcriptome studies, but also genomes and metagenomes.\n\nGo to SRA database: https://www.ncbi.nlm.nih.gov/sra, and search for ‚Äòcyanophora paradoxa‚Äô.\n\n\n\n\nScreenshot of the search result of C. paradoxa in the database NCBI SRA. Here you can see all sequencing libraries of this species that have been submitted to NCBI. You can specify which items are of interest or customize the search using the filter box on the left and right sides of the screen.\n\n\n\nWe‚Äôll adjust our selection using the tool in the SRA database, the SRA Run Selector, as follows.\n\n\n\n\nBrowsing sequencing data in NCBI SRA database\n\n\n\nIn the SRA Run Selector, you can customize the filters based on the metadata columns of all runs. In this case, we filter the SRA runs based on the assay type as RNA-Seq and select only paired-end sequencing data as follows.\n\n\n\n\nCustomizing filters in SRA Run Selector\n\n\n\nThen you can select which runs you want to download and perform analysis. In this workshop we‚Äôll select C. paradoxa RNA-Seq reads from SRR8306028, SRR8306029, SRR8306032, SRR8306033, SRR8306034 and SRR8306035.\n\n\n\n\nExporting the selected metadata in SRA Run Selector.\n\n\n\nThe downloaded metadata is in comma-separated file format. So you can open them with spreadsheet programs like Microsoft Excel on your local laptop. The metadata looks like this.\n\n\n\n\n\n \n  \n    Run \n    Assay.Type \n    AvgSpotLen \n    Bases \n    BioSample \n    Bytes \n    Center.Name \n    Consent \n    DATASTORE.filetype \n    DATASTORE.provider \n    DATASTORE.region \n    Experiment \n    Instrument \n    Library.Name \n    LibraryLayout \n    LibrarySelection \n    LibrarySource \n    Organism \n    Platform \n    ReleaseDate \n    create_date \n    version \n    Sample.Name \n    SRA.Study \n    BioProject \n    ENA.FIRST.PUBLIC..run. \n    ENA_first_public \n    ENA.LAST.UPDATE..run. \n    ENA.LAST.UPDATE \n    External_Id \n    INSDC_center_alias \n    INSDC_center_name \n    INSDC_first_public \n    INSDC_last_update \n    INSDC_status \n    Sample_Name \n    Submitter_Id \n    Broker_name \n    Developmental_stage \n    Experimental_Factor._stimulus..exp. \n    Genotype \n    growth_condition \n    Organism_part \n    stimulus \n    Experimental_Factor._organism..exp. \n    Experimental_Factor._time..exp. \n    Experimental_Factor._growth_condition..exp. \n    common_name \n    BioSampleModel \n    geo_loc_name_country \n    geo_loc_name_country_continent \n    geo_loc_name \n    Isolate \n    TISSUE \n    Collection_Date \n    Isolation_source \n    BIOMATERIAL_PROVIDER \n    dev_stage \n    Temp \n    TREATMENT \n    BREED \n    culture.collection \n    sequencer \n    source_mat_id \n    tissue_type \n    Host \n    Lat_Lon \n    Sample_Type \n    Strain \n  \n \n\n  \n    SRR8306028 \n    RNA-Seq \n    300 \n    3373326900 \n    SAMN10588740 \n    1950953927 \n    HHU DUESSELDORF \n    public \n    fastq,run.zq,sra \n    s3,ncbi,gs \n    gs.US,s3.us-east-1,ncbi.public \n    SRX5120515 \n    Illumina HiSeq 2000 \n    Cyanophora dark III \n    PAIRED \n    cDNA \n    TRANSCRIPTOMIC \n    Cyanophora paradoxa \n    ILLUMINA \n    2019-08-05T00:00:00Z \n    2018-12-17T16:48:00Z \n    1 \n    Cyanophora_dark \n    SRP173157 \n    PRJNA509798 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    Plant \n    Denmark \n    Europe \n    Denmark: obtained from the Scandinavian culture collection of Algae & Protozoa (SCCAP) \n    SCCAP K-0262 \n    unicells \n    NA \n    NA \n    SCCAP K-0262 \n    exponential \n    15 ¬∞C \n    0 ¬µmol quanta m-2s-1 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n  \n  \n    SRR8306029 \n    RNA-Seq \n    300 \n    3361510200 \n    SAMN10588740 \n    1882426113 \n    HHU DUESSELDORF \n    public \n    run.zq,fastq,sra \n    s3,ncbi,gs \n    gs.US,s3.us-east-1,ncbi.public \n    SRX5120514 \n    Illumina HiSeq 2000 \n    Cyanophora dark II \n    PAIRED \n    cDNA \n    TRANSCRIPTOMIC \n    Cyanophora paradoxa \n    ILLUMINA \n    2019-08-05T00:00:00Z \n    2018-12-17T16:44:00Z \n    1 \n    Cyanophora_dark \n    SRP173157 \n    PRJNA509798 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    Plant \n    Denmark \n    Europe \n    Denmark: obtained from the Scandinavian culture collection of Algae & Protozoa (SCCAP) \n    SCCAP K-0262 \n    unicells \n    NA \n    NA \n    SCCAP K-0262 \n    exponential \n    15 ¬∞C \n    0 ¬µmol quanta m-2s-1 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n  \n  \n    SRR8306032 \n    RNA-Seq \n    300 \n    3378668400 \n    SAMN10588739 \n    1903910409 \n    HHU DUESSELDORF \n    public \n    sra,run.zq,fastq \n    gs,s3,ncbi \n    ncbi.public,gs.US,s3.us-east-1 \n    SRX5120511 \n    Illumina HiSeq 2000 \n    Cyanophora light II \n    PAIRED \n    cDNA \n    TRANSCRIPTOMIC \n    Cyanophora paradoxa \n    ILLUMINA \n    2019-08-05T00:00:00Z \n    2018-12-17T16:44:00Z \n    1 \n    Cyanophora_normal light \n    SRP173157 \n    PRJNA509798 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    Plant \n    Denmark \n    Europe \n    Denmark: obtained from the Scandinavian culture collection of Algae & Protozoa (SCCAP) \n    SCCAP K-0262 \n    unicells \n    NA \n    NA \n    SCCAP K-0262 \n    exponential \n    15 ¬∞C \n    ~ 50 ¬µmol quanta m-2s-1 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n  \n  \n    SRR8306033 \n    RNA-Seq \n    300 \n    3386020200 \n    SAMN10588739 \n    1892499340 \n    HHU DUESSELDORF \n    public \n    fastq,run.zq,sra \n    ncbi,s3,gs \n    gs.US,ncbi.public,s3.us-east-1 \n    SRX5120510 \n    Illumina HiSeq 2000 \n    Cyanophora light I \n    PAIRED \n    cDNA \n    TRANSCRIPTOMIC \n    Cyanophora paradoxa \n    ILLUMINA \n    2019-08-05T00:00:00Z \n    2018-12-17T16:35:00Z \n    1 \n    Cyanophora_normal light \n    SRP173157 \n    PRJNA509798 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    Plant \n    Denmark \n    Europe \n    Denmark: obtained from the Scandinavian culture collection of Algae & Protozoa (SCCAP) \n    SCCAP K-0262 \n    unicells \n    NA \n    NA \n    SCCAP K-0262 \n    exponential \n    15 ¬∞C \n    ~ 50 ¬µmol quanta m-2s-1 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n  \n  \n    SRR8306034 \n    RNA-Seq \n    300 \n    3436771500 \n    SAMN10588740 \n    1902846665 \n    HHU DUESSELDORF \n    public \n    fastq,run.zq,sra \n    ncbi,s3,gs \n    gs.US,ncbi.public,s3.us-east-1 \n    SRX5120509 \n    Illumina HiSeq 2000 \n    Cyanophora dark I \n    PAIRED \n    cDNA \n    TRANSCRIPTOMIC \n    Cyanophora paradoxa \n    ILLUMINA \n    2019-08-05T00:00:00Z \n    2018-12-17T16:38:00Z \n    1 \n    Cyanophora_dark \n    SRP173157 \n    PRJNA509798 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    Plant \n    Denmark \n    Europe \n    Denmark: obtained from the Scandinavian culture collection of Algae & Protozoa (SCCAP) \n    SCCAP K-0262 \n    unicells \n    NA \n    NA \n    SCCAP K-0262 \n    exponential \n    15 ¬∞C \n    0 ¬µmol quanta m-2s-1 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n  \n  \n    SRR8306035 \n    RNA-Seq \n    300 \n    3436308000 \n    SAMN10588739 \n    1909811743 \n    HHU DUESSELDORF \n    public \n    run.zq,fastq,sra \n    s3,gs,ncbi \n    gs.US,s3.us-east-1,ncbi.public \n    SRX5120508 \n    Illumina HiSeq 2000 \n    Cyanophora light III \n    PAIRED \n    cDNA \n    TRANSCRIPTOMIC \n    Cyanophora paradoxa \n    ILLUMINA \n    2019-08-05T00:00:00Z \n    2018-12-17T15:00:00Z \n    1 \n    Cyanophora_normal light \n    SRP173157 \n    PRJNA509798 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    Plant \n    Denmark \n    Europe \n    Denmark: obtained from the Scandinavian culture collection of Algae & Protozoa (SCCAP) \n    SCCAP K-0262 \n    unicells \n    NA \n    NA \n    SCCAP K-0262 \n    exponential \n    15 ¬∞C \n    ~ 50 ¬µmol quanta m-2s-1 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA"
  },
  {
    "objectID": "03_sra.html#downloading-sra-runs-using-fasterq-dump",
    "href": "03_sra.html#downloading-sra-runs-using-fasterq-dump",
    "title": "3¬† Data Retrieval with NCBI SRA Toolkit",
    "section": "3.3 Downloading SRA runs using fasterq-dump",
    "text": "3.3 Downloading SRA runs using fasterq-dump\nfasterq-dump are tools in the SRA toolkit used to connect from our remote server to the NCBI server and download sequencing data from SRA.\nAccording to the NCBI sra-tools‚Äô guideline, using fasterq-dump in combination with another tool, prefetch, is the better way to download data because prefetch can be invoked at any time if the previous download accidentally failed. So it is not necessary to start the download from the beginning.\nHowever, prefetch can sometimes be skipped if you want to download a small amount of data. In this workshop we‚Äôll use only fasterq-dump to download and process SRA file format to FASTQ file for further analysis.\n\n\n\n\n\n\nActivity\n\n\n\nWe‚Äôll do the following command in Terminal or MobaXterm, by access to the username and password that we‚Äôve provided.\n\nFor mobaXterm, enter to your session.\nFor terminal, type\n\nssh <username>@<server IP address>\nNow we download RNA-Seq libraries from C. paradoxa using the SRA accessions listed in the first column of the metadata above using the following command.\nActivate analysis environment\nconda activate ncbi\nGo to working directory\ncd ~/Cpa_RNASeq/01_Rawdata\nRun fasterq-dump\nfasterq-dump --threads 2 --progress \\\nSRR8306028 SRR8306029 SRR8306032 \\\nSRR8306033 SRR8306034 SRR8306035\nFrom the fasterq-dump command,\n--threads refer to how many threads to use (default = 6).\n--progress force the terminal to print the progress of downloading and processing file to the screen.\nExpected output files.\n01_Rawdata\n‚îú‚îÄ‚îÄ SRR8306028_1.fastq\n‚îú‚îÄ‚îÄ SRR8306028_2.fastq\n‚îú‚îÄ‚îÄ SRR8306029_1.fastq\n‚îú‚îÄ‚îÄ SRR8306029_2.fastq\n‚îú‚îÄ‚îÄ SRR8306032_1.fastq\n‚îú‚îÄ‚îÄ SRR8306032_2.fastq\n‚îú‚îÄ‚îÄ SRR8306033_1.fastq\n‚îú‚îÄ‚îÄ SRR8306033_2.fastq\n‚îú‚îÄ‚îÄ SRR8306034_1.fastq\n‚îú‚îÄ‚îÄ SRR8306034_2.fastq\n‚îú‚îÄ‚îÄ SRR8306035_1.fastq\n‚îî‚îÄ‚îÄ SRR8306035_2.fastq\n\n\nBy default, fasterq-dump processes a single SRA file format of paired-end reads by splitting reads into forward (*_1.fastq) and reverse (*_2.fastq), if singletons (unpaired between forward and reverse reads) present, it will be written to another fastq file as described in this figure.\n\n\n\nSequence read processing by fasterq-dump using default parameters. Figure adopted from https://github.com/ncbi/sra-tools/wiki/HowTo:-fasterq-dump."
  },
  {
    "objectID": "03_sra.html#reference-sources",
    "href": "03_sra.html#reference-sources",
    "title": "3¬† Data Retrieval with NCBI SRA Toolkit",
    "section": "3.4 Reference Sources",
    "text": "3.4 Reference Sources\n\nPrice, Dana C., et al.¬†‚ÄúCyanophora paradoxa genome elucidates origin of photosynthesis in algae and plants.‚Äù Science 335.6070 (2012): 843-847. https://doi.org/10.1126/science.1213561.\nSRA Toolkit: the SRA database at your fingertips from NCBI Insights. Accessed 4-Mar-2023.\nHow to use NCBI SRA Toolkit effectively by Renesh Bedre, Data science blog. Accessed 4-Mar-2023.\nHowTo: fasterq dump by NCBI sra-tools GitHub Wiki. Accessed 4-Mar-2023."
  },
  {
    "objectID": "04_qc.html#what-is-fastq-file-format",
    "href": "04_qc.html#what-is-fastq-file-format",
    "title": "4¬† RNA-Seq Data Quality Control",
    "section": "4.1 What is FASTQ file format",
    "text": "4.1 What is FASTQ file format\nNext-generation sequencing and data analysis projects typically begin with the processing of sequence read data and their quality tags from the sequencer in FASTQ format. The FASTQ format is the most commonly used format in sequence analysis and is generated by a sequencer. The FASTQ file contains the sequence data from the clusters that pass the filter of a flow cell. Many analysis tools require this format because it contains much more information than FASTA. In this workshop, we will mainly explain the FASTQ file format, which comes from the Illumina sequencer.\nThe FASTQ format is similar to the fasta format, but differs in syntax and in the integration of quality values. Each sequence requires at least 4 lines:\n\n\n\nExample of FASTQ file format\n\n\n\nA sequence identifier with information about the sequencing run and the cluster. The exact contents of this line vary by based on the BCL to FASTQ conversion software used.\nThe sequence (the base calls; A, C, T, G and N).\nA separator, which is simply a plus (+) sign.\nThe base call quality scores. These are Phred +33 encoded, using ASCII characters to represent the numerical quality scores.\n\nThe FastQ sequence descriptor generally follows a specific format that includes all information about the sequencer and its position on the flow cell. The sequence descriptor also follows a specific format and contains information about the sample information.\nFASTQ sequence descriptor, particulary in Illumina sequence reads look like:\n@HWUSI-EAS100R:6:73:941:1973#0/1\nwhere\n\n\n\n\n\n\n\nHWUSI-EAS100R\nThe unique instrument name\n\n\n6\nFlowcell lane\n\n\n73\nTile number within the flowcell lane\n\n\n941\n‚Äòx‚Äô-coordinate of the cluster within the tile\n\n\n1973\n‚Äòy‚Äô-coordinate of the cluster within the tile\n\n\n#0\nIndex number for a multiplexed sample (0 for no indexing)\n\n\n/1\nThe member of a pair, /1 or /2 (paired-end or mate-pair reads only)\n\n\n\nAs mentioned earlier, line 4 contains the quality score of the nucleotide at the same position. The quality scores are represented by the code ASCII, which indicates how confident of the correctly called base is.\nWe can calculate the quality score of a base,if P is the error probability, then:\n\\[\n\\text{Q} = \\text{-10}log_{10}\\left( P \\right)\n\\]\nThe following figure shows the representative ASCII code for the score value. Base quality scoring for analysis is important when identifying types of genomic variation such as SNPs, but it is also an indicator of the overall quality of the sequencing as well.\n\n\n\nTables converting between integer Q scores, ASCII characters and error probabilities. Figure adopted from https://www.drive5.com/usearch/manual/quality_score.html\n\n\n\n4.1.1 What software use FASTQ\nTo date, Almost NGS analysis software requires FASTQ format. For example:\n\nQC such as fastQC used FASTQ to determine how good of the sequence read library, generate an informative report, and also determining the presence of adapter sequences which can also be trimmed by some integrated QC tools such as FASTP.\nAligners such as bowtie2, BWA, STAR, and so on, use reads, and quality sometimes, to align to the reference sequence. The mapping information can be further used for quantifying expression, constructing sequence assembly, and variant calling.\nDe novo assembly tools, for example Trinity, Spades, Velvet, etc., also use FASTQ to construct contig library and scaffolding. Some de novo assembler tools not only use FASTQ to contruct draft assembly but also used in the polishing process to refine assembly, such as Flye, Unicycler, Canu, etc."
  },
  {
    "objectID": "04_qc.html#quality-assessment-using-fastqc",
    "href": "04_qc.html#quality-assessment-using-fastqc",
    "title": "4¬† RNA-Seq Data Quality Control",
    "section": "4.2 Quality assessment using FastQC",
    "text": "4.2 Quality assessment using FastQC\nFastQC is designed for quality control of raw sequence data from high-throughput sequencing technology. It provides a modular set of analyses that you can use to get a quick overview of the quantity and quality of your data, and to help you decide on the raw data whether you should perform adapter or low-quality read trimming or whether you can perform further analyses. For sequence reads that require adapter trimming before further analysis, we recommended to assessing the quality both before and after trimming.\nMost sequencers will generate a QC report as part of their analysis pipeline, but this is usually only focused on identifying problems which were generated by the sequencer itself. FastQC aims to provide a QC report which can spot problems which originate either in the sequencer or in the starting library material.\n\n\n\n\n\n\nActivity\n\n\n\nThe following will perform on you user account by activating your working environment at first.\nconda activate qc\nThen, create a directory for QC result before adapter trimming\nmkdir 02_QC/fastQC_before_trim\nRun FastQC all file at once. Here, we‚Äôll use a wildcard *.fastq to select all FASTQ files in 01_Rawdata directory. We also specify number of CPU threads in --threads and QC output files in 02_QC/fastQC_before_trim using --outdir argument.\nfastqc --outdir 02_QC/fastQC_before_trim \\\n--threads 2 \\\n01_Rawdata/*.fastq"
  },
  {
    "objectID": "04_qc.html#interpreting-fastqc-results",
    "href": "04_qc.html#interpreting-fastqc-results",
    "title": "4¬† RNA-Seq Data Quality Control",
    "section": "4.3 Interpreting FastQC results",
    "text": "4.3 Interpreting FastQC results\nFastQC also provided excellent explanation of each analysis step in their documentation. So we encouraged you to learn more at their web page along with the documentation.\nThe analysis in FastQC is performed by a series of analysis modules. The left hand side of the main interactive display or the top of the HTML report show a summary of the modules which were run, and a quick evaluation of whether the results of the module seem entirely normal (green tick), slightly abnormal (orange triangle) or very unusual (red cross).\n\n\n\nFastQC sidebar\n\n\n\n4.3.1 Basic statistics\nThe Basic Statistics module generates some simple composition statistics for the file analysed.\n\n\n\nBasic statistics of SRR8306028.\n\n\n\nFilename: The original filename of the file which was analysed\nFile type: Says whether the file appeared to contain actual base calls or colorspace data which had to be converted to base calls\nEncoding: Says which ASCII encoding of quality values was found in this file.\nTotal Sequences: A count of the total number of sequences processed. There are two values reported, actual and estimated. At the moment these will always be the same. In the future it may be possible to analyse just a subset of sequences and estimate the total number, to speed up the analysis, but since we have found that problematic sequences are not evenly distributed through a file we have disabled this for now.\nSequence Length: Provides the length of the shortest and longest sequence in the set. If all sequences are the same length only one value is reported. %GC: The overall %GC of all bases in all sequences\n\n\n\n4.3.2 Per Base Sequence Quality\nThe Per base sequence quality plot shows an overview of the range of quality values across all bases at each position in the FastQ file.\n\n\n\nPer Base Sequence Quality plot of SRR8306028. In which the central red line is the median value. The yellow box represents the inter-quartile range (25-75%). The upper and lower whiskers represent the 10% and 90% points. The blue line represents the mean quality.\n\n\nThe higher the score, the better the base call, i.e., the box plots fall into the very good quality area (green background), the mediocre quality area (orange background), and the poor quality area (red background). The following figures show a comparison of the good and poor quality results of Illumina sequencing technology.\n\n\n\nA comparison of good (left) and bad (right) per base sequence quality plots. Figures adopted from example reports in https://www.bioinformatics.babraham.ac.uk/projects/fastqc.\n\n\n\n\n4.3.3 Per tile sequence quality\nThis plot is specific to Illumina sequencing libraries and shows colour shading of quality score by position on the flow cell. The colours are on a scale from cold to hot, with cold colours representing positions where the quality was at or above average for that base in the run, and hotter colours indicating that a tile had worse qualities than other tiles for that base. In the example below, you can see that certain tiles have consistently poor quality. A good chart should be blue throughout.\n\n\n\nPer tile sequence quality plot of SRR8306028.\n\n\n\n\n4.3.4 Per Sequence Quality Scores\nThe per sequence quality score report allows you to see if a subset of your sequences have universally low quality values. It is often the case that a subset of sequences will have universally poor quality, often because they are poorly imaged (on the edge of the field of view etc), however these should represent only a small percentage of the total sequences.\n\n\n\nPer Sequence Quality Scores plot of SRR8306028.\n\n\n\n\n4.3.5 Per Base Sequence Content\nPer Base Sequence Content plots out the proportion of each base position in a file for which each of the four normal DNA bases has been called. The plot shows the quality of nucleotide A T C and G separately into 4 lines.\n\n\n\nPer Base Sequence Content plot of SRR8306028.\n\n\nUsually ambiguous base values are found at the beginning of the read. Libraries made with random hexamer primers, with almost all RNA-Seq libraries using them, and those that were fragmented libraries. This bias does not affect an absolute sequence, but provides enrichment of a number of different K-mers at the 5‚Äô end of the reads. While this is a true technical bias, it cannot be corrected by trimming and does not appear to affect downstream analysis in most cases. However, a warning or error is generated in this module. This module issues a warning if the difference between A and T, or G and C is greater than 10% in any position.\n\n\n4.3.6 Per Sequence GC Content\nThis module measures the GC content over the entire length of each sequence in a file and compares it to a normal distribution of GC content. Normally, one would expect an approximately normal distribution of GC content, where the central peak corresponds to the total GC content of the underlying genome of interest.\nThe skewness of the distribution may indicate some unusual events such as contamination or systematic bias in your sequencing library. However, the GC content signature of different organisms may depend on their nature.\n\n\n\nPer Sequence GC Content plot of SRR8306028.\n\n\n\n\n4.3.7 Per base N content\nThis module represents the percentage of base calls at each position for which an N was called. The ‚ÄòN‚Äô base is found when the sequencer is not able to make a confident base call, then it will normally substitute an N.\n\n\n\nPer base N content plot of SRR8306028.\n\n\n\n\n4.3.8 Sequence Length Distribution\nThis module generates a histogram of distribution of sequence reads in the file which was analyzed.\n\n\n\nSequence Length Distribution plot of SRR8306028.\n\n\n\n\n4.3.9 Sequence Duplication Levels\nThis module counts the degree of duplication for every sequence in a library and creates a plot showing the relative number of sequences with different degrees of duplication. A low level of duplication may indicate a very high level of coverage of the target sequence, but a high level of duplication is more likely to indicate some kind of enrichment bias (eg PCR over amplification).\n\n\n\nSequence Duplication Levels plot of SRR8306028.\n\n\n\n\n4.3.10 Overrepresented sequences\nThis module lists all sequences that make up more than 0.1% of the first 100,000 sequences examined. For each overrepresented sequence, the program searches for matches in a database of common impurities and reports the best match found. However, finding a hit doesn‚Äôt mean that this is the source of the contamination, but may point you in the right direction.\n\n\n4.3.11 Adapter Content\nThis plot shows the cumulative percentage of adapter sequences used for sequencing this library at each position. Most adapter sequences found in Illumina RNA-Seq libraries are Illumina Universal Adapters. This module issues a warning if a sequence is present in more than 5% of all reads. This module issues a warning if a sequence is present in more than 10% of all reads. If the adapter sequence is present in more than 1% of the sequence library, adapter trimming is considered.\n\n\n\nAdapter Content of SRR8306028.\n\n\n\n\n\n\n\n\nActivity\n\n\n\nTo further combine all the QC results into a single interactive HTML file, we‚Äôd suggested to use multiqc software to combine it.\nconda activate qc\nThen, run multiqc\nmultiqc --filename QCreport_before_trim \\\n--outdir 02_QC/ \\\n--dirs 02_QC/fastQC_before_trim/\nOutput files:\n- QCreport_before_trim_data\n   ‚îú‚îÄ‚îÄ multiqc_citations.txt\n   ‚îú‚îÄ‚îÄ multiqc_data.json\n   ‚îú‚îÄ‚îÄ multiqc_fastqc.txt\n   ‚îú‚îÄ‚îÄ multiqc_general_stats.txt\n   ‚îú‚îÄ‚îÄ multiqc.log\n   ‚îî‚îÄ‚îÄ multiqc_sources.txt\n- QCreport_before_trim.html"
  },
  {
    "objectID": "04_qc.html#adapter-trimming-with-cutadapt",
    "href": "04_qc.html#adapter-trimming-with-cutadapt",
    "title": "4¬† RNA-Seq Data Quality Control",
    "section": "4.4 Adapter Trimming with Cutadapt",
    "text": "4.4 Adapter Trimming with Cutadapt\nCutadapt is a tool to remove sequencing adapters, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads. Cutadapt supports both FASTQ and FASTA file format for trimming.\nSeveral types of sequencing adapters have been used nowaday. We have to know which adapter found in our sequencing library. Fortunately, Illumina provide a manual of Illumina Adapter Sequences that used in different types of sequencing. As mentioned, most of RNA-Seq library sequenced by Illumina used Illumina TruSeq Single Indexes, which is AGATCGGAAGAGCACACGTCTGAACTCCAGTCA and AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT flanked at the 5‚Äô end of forward reads and 3‚Äô end of reverse reads, respectively.\nFortunately, the dataset that will be used is free of apadter sequences examined from the adapter content from FastQC result. So this command will just show as a demo for your future project.\nAn example command of Cutadapt as follow.\ncutadapt --cores 2 \\\n-u 10 -U 10 \\\n-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA \\\n-A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT \\\n-o <output_forward.fastq> \\\n-p <output_reverse.fastq> \\\n<input_forward.fastq> <input_reverse.fastq>\nAccording to the command, we specify number of CPU threads in --cores. We remove 10 bases directly from each end of read, -u for forward and -U for reverse reads. Then we specify the adapter sequences as mentioned above in a and A. And the paths for forward and reverse reads output files in -o and -p, respectively."
  },
  {
    "objectID": "04_qc.html#reference-sources",
    "href": "04_qc.html#reference-sources",
    "title": "4¬† RNA-Seq Data Quality Control",
    "section": "4.5 Reference Sources",
    "text": "4.5 Reference Sources\n\nQuality Control of FASTQ files from Harvard Chan Bioinformatics Core (HBC) training (Accessed on 1 Mar 2023).\nFastQC official website from Babraham Bioinformatics (Accessed on 1 Mar 2023).\nFastQC Documentation from Babraham Bioinformatics (Accessed on 1 Mar 2023).\nCutadapt 4.2 Documentation (Accessed on 1 Mar 2023).\nIllumina Adapter Sequences (Accessed on 1 Mar 2023)."
  },
  {
    "objectID": "06_de_analysis.html#estimating-transcript-abundance",
    "href": "06_de_analysis.html#estimating-transcript-abundance",
    "title": "6¬† Estimating Abundance and Differential Expression Analysis of Genes",
    "section": "6.1 Estimating Transcript Abundance",
    "text": "6.1 Estimating Transcript Abundance\nThis part will adopted from Trinity‚Äôs Wiki Trinity Transcript Quantification.\nThere are two different methods for quantifying reads mapped to the reference, by using the alignment-based (RSEM) and alignment-free (salmon, kallisto) qualtifiers. In this workshop, we‚Äôll use the salmon, an ultra-fast alignment and quantification tool, to count number of reads mapped to the assembled gene.\n\n\n\n\n\n\nTip\n\n\n\nYou can see the usage of the command you wsh to perform by type the command followed by --help, or -h. For example, to see the usage of\nalign_and_estimate_abundance.pl -h\n\n\n\n\n\n\n\n\nActivity\n\n\n\nNow we will align and count reads mapped to the reference assembled transcripts using buit-in utility align_and_estimate_abundance.pl using the following commands.\n\nGo to working directory\ncd ~/Cpa_RNASeq\nThe working directory should contain the following subdirectories.\n\n        Cpa_RNASeq\n        ‚îú‚îÄ‚îÄ 01_Rawdata\n        ‚îú‚îÄ‚îÄ 02_QC\n        ‚îú‚îÄ‚îÄ 03_assembly\n        ‚îú‚îÄ‚îÄ 04_DE_analysis\n        ‚îî‚îÄ‚îÄ 05_annotation\n\nEstimating Transcript Abundance\nalign_and_estimate_abundance.pl \\\n--transcripts 03_assembly/trinity_out_dir.Trinity.fasta \\\n--seqType fq \\\n--samples_file sample_list.tsv \\\n--est_method salmon \\\n--gene_trans_map 03_assembly/trinity_out_dir.Trinity.fasta.gene_trans_map \\\n--thread_count 2 \\\n--prep_reference\n\n\n\nParameter descriptions of align_and_estimate_abundance.pl: the assembled transcripts flagged in --transcripts, --seqType indicates file format of reads that will be mappped to the reference transcripts.\nA list of read files will be contained in the metadata file sample_list.tsv in the parameter --samples_file, which we have prepared for you. In short, the sample list will be prepared in a tab-delimited text file indicating the relationships between biological replicates. For example,\ndark    dark_1  01_Rawdata/SRR8306034_1.fastq   01_Rawdata/SRR8306034_2.fastq\ndark    dark_2  01_Rawdata/SRR8306029_1.fastq   01_Rawdata/SRR8306029_2.fastq\ndark    dark_3  01_Rawdata/SRR8306028_1.fastq   01_Rawdata/SRR8306028_2.fastq\nnormal_light    normal_light_1  01_Rawdata/SRR8306033_1.fastq   01_Rawdata/SRR8306033_2.fastq\nnormal_light    normal_light_2  01_Rawdata/SRR8306032_1.fastq   01_Rawdata/SRR8306032_2.fastq\nnormal_light    normal_light_3  01_Rawdata/SRR8306035_1.fastq   01_Rawdata/SRR8306035_2.fastq\nThe first column indicates the study experimental groups, followed by their biological replicates in the second column, and the forward and reverse sequence read files belong to their biological replicate. It‚Äôs important that the file path begins with the directory in which you‚Äôll be working so that the programs can correctly route to the files.\nNext, define the read count estimation tool in --est_method, in this workshop we‚Äôll use salmon, and also estimate gene-level read counts using information about gene-transcript relationships from the trinity_out_dir.Trinity.fasta.gene_trans_map file that we specified in the --gene_trans_map parameter.\nOutput results are created in the current working directory separately for experimental groups and biological replicates.\ndark_1\n    ‚îú‚îÄ‚îÄ aux_info/\n    ‚îú‚îÄ‚îÄ cmd_info.json\n    ‚îú‚îÄ‚îÄ lib_format_counts.json\n    ‚îú‚îÄ‚îÄ libParams/\n    ‚îú‚îÄ‚îÄ logs/\n    ‚îú‚îÄ‚îÄ quant.sf\n    ‚îî‚îÄ‚îÄ quant.sf.genes\n.\n.\n.\nnormal_light_3\n    ‚îú‚îÄ‚îÄ aux_info/\n    ‚îú‚îÄ‚îÄ cmd_info.json\n    ‚îú‚îÄ‚îÄ lib_format_counts.json\n    ‚îú‚îÄ‚îÄ libParams/\n    ‚îú‚îÄ‚îÄ logs/\n    ‚îú‚îÄ‚îÄ quant.sf\n    ‚îî‚îÄ‚îÄ quant.sf.genes\n\n\n\n\n\n\nActivity\n\n\n\nAccording to the previous part, now we‚Äôll organize the directory to make it tidy by moving all the results to the directory 04_ DE _analysis.\n``` bash\n# make sure you're in ~/Cpa_RNASeq directory so that you can move the file correctly. \nmv dark* normal* 04_DE_analysis/\n```\n\nThen enter to the directory `04_DE_analysis`\n\n``` bash\ncd 04_DE_analysis\nls ./*\n```\n\n\nExpected result:\n(trinity) jiratchaya@pslab1:~/Cpa_RNASeq/04_DE_analysis$ ls ./*\n./dark_1:\naux_info  cmd_info.json  lib_format_counts.json  libParams  logs  quant.sf  quant.sf.genes\n\n./dark_2:\naux_info  cmd_info.json  lib_format_counts.json  libParams  logs  quant.sf  quant.sf.genes\n\n./dark_3:\naux_info  cmd_info.json  lib_format_counts.json  libParams  logs  quant.sf  quant.sf.genes\n\n./normal_light_1:\naux_info  cmd_info.json  lib_format_counts.json  libParams  logs  quant.sf  quant.sf.genes\n\n./normal_light_2:\naux_info  cmd_info.json  lib_format_counts.json  libParams  logs  quant.sf  quant.sf.genes\n\n./normal_light_3:\naux_info  cmd_info.json  lib_format_counts.json  libParams  logs  quant.sf  quant.sf.genes\nafter running salmon you‚Äôll find output files:\n\nquant.sf : transcript abundance estimates (generated by salmon)\nquant.sf.genes : gene-level abundance estimates (generated here by summing transcript values)\n\nHere‚Äôs an example of quant.sf.genes file:\n\n\n\n\n \n  \n    Name \n    Length \n    EffectiveLength \n    TPM \n    NumReads \n  \n \n\n  \n    TRINITY_DN35101_c0_g1 \n    248 \n    35.30 \n    0.00 \n    0.00 \n  \n  \n    TRINITY_DN42970_c0_g1 \n    215 \n    24.82 \n    7.15 \n    3.00 \n  \n  \n    TRINITY_DN41199_c0_g1 \n    280 \n    47.38 \n    0.00 \n    0.00 \n  \n  \n    TRINITY_DN35784_c0_g1 \n    247 \n    34.96 \n    6.77 \n    4.00 \n  \n  \n    TRINITY_DN32682_c0_g1 \n    275 \n    45.30 \n    0.00 \n    0.00 \n  \n  \n    TRINITY_DN8538_c0_g1 \n    1019 \n    710.33 \n    0.17 \n    2.00 \n  \n  \n    TRINITY_DN2880_c0_g1 \n    2376 \n    2067.33 \n    0.74 \n    26.00 \n  \n  \n    TRINITY_DN9226_c0_g1 \n    275 \n    45.30 \n    7.84 \n    6.00 \n  \n  \n    TRINITY_DN3645_c1_g1 \n    1175 \n    866.33 \n    0.40 \n    5.82 \n  \n  \n    TRINITY_DN5921_c0_g2 \n    368 \n    94.72 \n    4.37 \n    7.00"
  },
  {
    "objectID": "06_de_analysis.html#building-transcript-and-gene-expression-matrices",
    "href": "06_de_analysis.html#building-transcript-and-gene-expression-matrices",
    "title": "6¬† Estimating Abundance and Differential Expression Analysis of Genes",
    "section": "6.2 Building Transcript and Gene Expression Matrices",
    "text": "6.2 Building Transcript and Gene Expression Matrices\nWe use gene-level abundance matrices with the filename quant.sf.genes, which are available in all results directories. In this step, the utility abundance_estimates_to_matrix.pl is used to combine all separate count matrices from the file quant.sf.genes in all result directories into a single matrix file. By using salmon as --est_method and specifying the parameter --gene_trans_map, a gene abundance matrix is created.\n\n\n\n\n\n\nActivity\n\n\n\n\nCreate abundance matrix\nabundance_estimates_to_matrix.pl --est_method salmon \\\n--gene_trans_map ../03_assembly/trinity_out_dir.Trinity.fasta.gene_trans_map \\\n--name_sample_by_basedir \\\n*/quant.sf.genes\nExpected result:\n(trinity) jiratchaya@pslab1:~/Cpa_RNASeq/04_DE_analysis$ ls -l\ntotal 4945\ndrwxrwx--- 1 root PSLab    4096 Mar  5 16:16 dark_1\ndrwxrwx--- 1 root PSLab    4096 Mar  5 16:16 dark_2\ndrwxrwx--- 1 root PSLab    4096 Mar  5 16:16 dark_3\ndrwxrwx--- 1 root PSLab    4096 Mar  5 16:16 normal_light_1\ndrwxrwx--- 1 root PSLab    4096 Mar  5 16:16 normal_light_2\ndrwxrwx--- 1 root PSLab    4096 Mar  5 16:16 normal_light_3\n-rw-rw---- 1 root PSLab      67 Mar  6 13:29 salmon.gene.counts.matrix\n-rw-rw---- 1 root PSLab      67 Mar  6 13:29 salmon.gene.TPM.not_cross_norm\n-rw-rw---- 1 root PSLab 2736773 Mar  6 13:29 salmon.isoform.counts.matrix\n-rw-rw---- 1 root PSLab 2297101 Mar  6 13:29 salmon.isoform.TPM.not_cross_norm\nThis command will generate 4 result files:\n\nsalmon.gene.counts.matrix is the estimated raw RNA-Seq counts in GENE level in all experimental groups.\nsalmon.gene.TPM.not_cross_norm is the Transcript per Million (TPM) of RNA-Seq counts in GENE level in all experimental groups.\nsalmon.isoform.counts.matrix is the estimated raw RNA-Seq counts in TRANSCRIPTS level in all experimental groups.\nsalmon.isoform.TPM.not_cross_norm is the Transcript per Million (TPM) of RNA-Seq counts in TRANSCRIPTS level in all experimental groups."
  },
  {
    "objectID": "06_de_analysis.html#quality-control-of-sample-read-counts-and-biological-replicates",
    "href": "06_de_analysis.html#quality-control-of-sample-read-counts-and-biological-replicates",
    "title": "6¬† Estimating Abundance and Differential Expression Analysis of Genes",
    "section": "6.3 Quality Control of Sample Read Counts and Biological Replicates",
    "text": "6.3 Quality Control of Sample Read Counts and Biological Replicates\nOnce you‚Äôve performed quantification for each experimental group, it‚Äôs good to examine the data to ensure that your biological replicates are well correlated, and also to investigate relationships among your samples.\nIt is critical that you identify any obvious differences between the relationships between your sample and replicates, such as those resulting from accidental mislabeling of sample replicates, strong outliers, or batch effects, prior to further data analysis.\nThe Trinity‚Äôs utility called PtR (pronounced as ‚ÄòPeter‚Äô, stands for Perl to R) can generate some exploratory data analysis that rely on count matrix, such as compare difference between replicate, compare difference between experimental groups, principal component analysis, and so on.\n\n\n\n\n\n\nActivity\n\n\n\nRecheck the current working directory\npwd\nYou‚Äôre in ~/Cpa_RNASeq/04_DE_analysis\n\nPrepare sample metadata from differential expression (DE) analysis\nThe sample metadata table for analysis DE is different from the table used to estimate abundance. We only need the first two columns from this file to create a metadata table for analysis from DE. Therefore, we can use the following Bash command to create and edit a new file.\n# Go to ~/Cpa_RNASeq directory by change to upper directory\ncd ..\nExtract first 2 columns of the metadata for estimating read count to to a new file in 04_DE_analysis\ncut -f 1-2 sample_list.tsv > 04_DE_analysis/samples.txt\nThen dive back into 04_DE_analysis directory\ncd 04_DE_analysis\nSee expected result file\n(trinity) jiratchaya@pslab1:~/Cpa_RNASeq/04_DE_analysis$ cat samples.txt\ndark    dark_1\ndark    dark_2\ndark    dark_3\nnormal_light    normal_light_1\nnormal_light    normal_light_2\nnormal_light    normal_light_3\n\n\n\n\n6.3.1 Compare replicates for each of your samples\nThis step will use PtR to reads the matrix of counts, performs a counts-per-million (CPM) data transformation followed by a log2 transform, and then generates a multi-page pdf file named ${sample}.rep_compare.pdf for each of your samples, including several useful plots\n\n\n\n\n\n\nActivity\n\n\n\nCompare replicates for each of your samples\n\n``` bash\nPtR --matrix salmon.isoform.counts.matrix \\\n--samples samples.txt --log2 --CPM \\\n--min_rowSums 10 \\\n--compare_replicates\n```\n\n\nThese files will append more to your current working directories:\n-rw-rw---- 1 root PSLab    4695 Mar  6 14:37 salmon.isoform.counts.matrix.R\n-rw-rw---- 1 root PSLab 1990182 Mar  6 14:37 dark.rep_compare.pdf\n-rw-rw---- 1 root PSLab 1828692 Mar  6 14:37 normal_light.rep_compare.pdf\n-rw-rw---- 1 root PSLab 3558147 Mar  6 14:37 salmon.isoform.counts.matrix.minRow10.CPM.log2.dat\nThe last 3 files are newly generated by this step. There‚Äôs two PDF files separated by experimental groups, dark.rep_compare.pdf and normal_light.rep_compare.pdf, and raw data for plots in .dat file.\n\n\n\nExample result of comparing biological replicates in Dark samples. The figures were captured from dark.rep_compare.pdf file. (A) The sum of mapped fragments. (B) Pairwise comparisons of replicate log(CPM) values, in which the data points more than 2-fold different are highlighted in red. (C) The pairwise MA plots (x-axis: mean log(CPM), y-axis log(fold_change)). And, (D) A Replicate Pearson correlation heatmap.\n\n\n\n\n6.3.2 Compare Replicates Across Samples\n\n\n\n\n\n\nActivity\n\n\n\nThis command will generate a useful heatmap of pearson correlation matrix of samples from two different experimental groups.\n    PtR --matrix salmon.isoform.counts.matrix \\\n    --min_rowSums 10 \\\n    --samples_file samples.txt \\\n    --log2 --CPM \\\n    --sample_cor_matrix\n\n\nThese files will append more to your current working directories:\n-rw-rw---- 1 root PSLab    4012 Mar  6 15:02 salmon.isoform.counts.matrix.R\n-rw-rw---- 1 root PSLab 3558147 Mar  6 15:02 salmon.isoform.counts.matrix.minRow10.CPM.log2.dat\n-rw-rw---- 1 root PSLab     678 Mar  6 15:02 salmon.isoform.counts.matrix.minRow10.CPM.log2.sample_cor.dat\n-rw-rw---- 1 root PSLab    6429 Mar  6 15:02 salmon.isoform.counts.matrix.minRow10.CPM.log2.sample_cor_matrix.pdf\n\n\n\nheatmap of pearson correlation coefficiant between Dark and Normal light samples.\n\n\n\n\n6.3.3 Principal Component Analysis (PCA)\nAnother important analysis method to explore relationships among the sample replicates is Principal Component Analysis (PCA).\nYou can find more explanation about PCA here: - https://blog.bioturing.com/2018/06/14/principal-component-analysis-explained-simply/ - https://youtu.be/FgakZw6K1QQ\n\n\n\n\n\n\nActivity\n\n\n\n    PtR --matrix salmon.isoform.counts.matrix \\\n    --samples_file samples.txt \\\n    --min_rowSums 10 --log2 \\\n    --CPM --center_rows \\\n    --prin_comp 3\n\n\nThese files will append more to your current working directories:\n-rw-rw---- 1 root PSLab    4789 Mar  6 15:18 salmon.isoform.counts.matrix.R\n-rw-rw---- 1 root PSLab 4069112 Mar  6 15:18 salmon.isoform.counts.matrix.minRow10.CPM.log2.centered.dat\n-rw-rw---- 1 root PSLab     756 Mar  6 15:18 salmon.isoform.counts.matrix.minRow10.CPM.log2.centered.PCA.prcomp.scores\n-rw-rw---- 1 root PSLab 4163653 Mar  6 15:18 salmon.isoform.counts.matrix.minRow10.CPM.log2.centered.PCA.prcomp.loadings\n-rw-rw---- 1 root PSLab    5446 Mar  6 15:18 salmon.isoform.counts.matrix.minRow10.CPM.log2.centered.prcomp.principal_components.pdf\nYou can find the PCA plot in salmon.isoform.counts.matrix.minRow10.CPM.log2.centered.prcomp.principal_components.pdf.\n\n\n\nPCA plot.\n\n\nWe set the number of principal components (PC) to be calculated for only first 3 PCs in --prin_comp. Which indicates that these PCs will be plotted, as shown above, with PC1 vs.¬†PC2 and PC2 vs.¬†PC3. In this example, the replicates cluster tightly according to sample type, which is very reassuring."
  },
  {
    "objectID": "06_de_analysis.html#differential-expression-analysis",
    "href": "06_de_analysis.html#differential-expression-analysis",
    "title": "6¬† Estimating Abundance and Differential Expression Analysis of Genes",
    "section": "6.4 Differential Expression Analysis",
    "text": "6.4 Differential Expression Analysis\nTrinity also contains a built-in utility for DE analysis called run_DE_analysis.pl, in which use the count matrix and sample metadata file. Trinity provides support for several differential expression analysis tools, currently including edgeR, DESeq2, limma/voom, and ROTS.\nDE analysis in Trinity will perform pairwise comparison of gene/transcript expression. If the biological replicates are presented for each sample, you should indicate this as we already created in our metadata table samples.txt. Here we‚Äôll analyze DE genes in the ‚Äòtranscript‚Äô level using the salmon.isoform.counts.matrix file.\n\n\n\n\n\n\nActivity\n\n\n\nDE analysis using DESeq2\nrun_DE_analysis.pl \\\n--matrix salmon.isoform.counts.matrix \\\n--method DESeq2 \\\n--samples_file samples.txt \\\n--output DESeq2_result\n\n\nAfter run the above command, the following directory will append to your current working directory:\ndrwxrwx--- 1 root PSLab     688 Mar  6 15:42 DESeq2_result\nIn this output directory, you‚Äôll find the following files for each of the pairwise comparisons performed:\n-rw-rw---- 1 root PSLab  972633 Mar  6 15:42 salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.count_matrix\n-rw-rw---- 1 root PSLab 4247784 Mar  6 15:42 salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results\n-rw-rw---- 1 root PSLab 2428272 Mar  6 15:42 salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.MA_n_Volcano.pdf\n-rw-rw---- 1 root PSLab    1845 Mar  6 15:42 salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.Rscript\nResult explanations:\n\nsalmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.Rscript is the R-script executed to perform the DE analysis.\nsalmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.count_matrix is an integer matrix of read count derived from the input file salmon.isoform.counts.matrix.\nsalmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results is the DE analysis results, including log fold change and statistical significance.\nsalmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.MA_n_Volcano.pdf is MA and Volcano plots features found DE at the defined FDR will be colored red.\n\nHere‚Äôs an example of DE analysis result file (salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results):\n\n\n\n\n \n  \n      \n    sampleA \n    sampleB \n    baseMeanA \n    baseMeanB \n    baseMean \n    log2FoldChange \n    lfcSE \n    stat \n    pvalue \n    padj \n  \n \n\n  \n    TRINITY_DN8082_c0_g1 \n    dark \n    normal_light \n    4685.731 \n    17.948650 \n    2351.8401 \n    8.023585 \n    0.3947937 \n    20.32349 \n    0 \n    0 \n  \n  \n    TRINITY_DN281_c0_g1 \n    dark \n    normal_light \n    2406.185 \n    9.827619 \n    1208.0061 \n    7.917578 \n    0.3987747 \n    19.85477 \n    0 \n    0 \n  \n  \n    TRINITY_DN902_c0_g1 \n    dark \n    normal_light \n    3515.942 \n    5.151569 \n    1760.5469 \n    9.433323 \n    0.4966128 \n    18.99533 \n    0 \n    0 \n  \n  \n    TRINITY_DN801_c0_g2 \n    dark \n    normal_light \n    2100.468 \n    4.052528 \n    1052.2602 \n    9.023139 \n    0.4877916 \n    18.49794 \n    0 \n    0 \n  \n  \n    TRINITY_DN38798_c0_g1 \n    dark \n    normal_light \n    1013.842 \n    4.511975 \n    509.1769 \n    7.806389 \n    0.4421257 \n    17.65649 \n    0 \n    0 \n  \n  \n    TRINITY_DN10456_c0_g1 \n    dark \n    normal_light \n    3630.296 \n    8.696336 \n    1819.4963 \n    8.698117 \n    0.5004932 \n    17.37909 \n    0 \n    0 \n  \n  \n    TRINITY_DN15271_c1_g1 \n    dark \n    normal_light \n    1503.228 \n    6.205016 \n    754.7166 \n    7.908525 \n    0.4612383 \n    17.14629 \n    0 \n    0 \n  \n  \n    TRINITY_DN258_c0_g2 \n    dark \n    normal_light \n    2973.655 \n    5.218821 \n    1489.4370 \n    9.144528 \n    0.5358879 \n    17.06425 \n    0 \n    0 \n  \n  \n    TRINITY_DN15130_c0_g1 \n    dark \n    normal_light \n    2019.010 \n    4.727083 \n    1011.8685 \n    8.728308 \n    0.5121991 \n    17.04085 \n    0 \n    0 \n  \n  \n    TRINITY_DN1_c0_g2 \n    dark \n    normal_light \n    1107.861 \n    6.860877 \n    557.3612 \n    7.312156 \n    0.4304045 \n    16.98903 \n    0 \n    0 \n  \n\n\n\n\n\nAn example of volcano plot for transcript-level differentially expression analysis.\n\n\n\n(left) MA plot and (right) volcano plot."
  },
  {
    "objectID": "06_de_analysis.html#extracting-and-clustering-differentially-expressed-transcripts",
    "href": "06_de_analysis.html#extracting-and-clustering-differentially-expressed-transcripts",
    "title": "6¬† Estimating Abundance and Differential Expression Analysis of Genes",
    "section": "6.5 Extracting and clustering differentially expressed transcripts",
    "text": "6.5 Extracting and clustering differentially expressed transcripts\nAn initial step in analyzing differential expression is to extract those transcripts that are most differentially expressed (most significant FDR and fold-changes) and to cluster the transcripts according to their patterns of differential expression across the samples.\n\n\n\n\n\n\nActivity\n\n\n\nExtracting and clustering differentially expressed transcripts can run using the following from within the DE output directory, by running the following script:\ncd DESeq2_result/\nanalyze_diff_expr.pl \\\n--matrix salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.count_matrix \\\n-P 0.001 \\\n-C 2 \\\n--samples ../samples.txt \\\n--max_genes_clust 10000\n\n\nThe above command use an integer count matrix from DE analysis, and define criteria for extracting differentially expressed transcripts. For example, set p-value cutoff for FDR in -P to 0.001, set minimum absolute log 2-fold change criteria in -C to 2, meaning that it will extracted only the DE transcripts that are 2^2 = 4-fold, and use only top 10,000 among all differentially transcripts in --max_genes_clust for hierarchical clustering analysis. However, user can customize these criteria based on their interest.\nThe following results will append to the current working directory DESeq2_result\n-rw-rw---- 1 root PSLab      120 Mar  6 16:34 salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.samples\n-rw-rw---- 1 root PSLab   332012 Mar  6 16:34 salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.P0.001_C2.dark-UP.subset\n-rw-rw---- 1 root PSLab    42038 Mar  6 16:34 salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.P0.001_C2.normal_light-UP.subset\n-rw-rw---- 1 root PSLab   373901 Mar  6 16:34 salmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.P0.001_C2.DE.subset\n-rw-rw---- 1 root PSLab       51 Mar  6 16:34 DE_feature_counts.P0.001_C2.matrix\n-rw-rw---- 1 root PSLab    73959 Mar  6 16:34 diffExpr.P0.001_C2.matrix\n-rw-rw---- 1 root PSLab     4649 Mar  6 16:34 diffExpr.P0.001_C2.matrix.R\n-rw-rw---- 1 root PSLab   246973 Mar  6 16:34 diffExpr.P0.001_C2.matrix.log2.centered.dat\n-rw-rw---- 1 root PSLab      698 Mar  6 16:34 diffExpr.P0.001_C2.matrix.log2.centered.sample_cor.dat\n-rw-rw---- 1 root PSLab     6399 Mar  6 16:34 diffExpr.P0.001_C2.matrix.log2.centered.sample_cor_matrix.pdf\n-rw-rw---- 1 root PSLab   101250 Mar  6 16:34 diffExpr.P0.001_C2.matrix.log2.centered.genes_vs_samples_heatmap.pdf\n-rw-rw---- 1 root PSLab 14777602 Mar  6 16:34 diffExpr.P0.001_C2.matrix.RData\nResult explanations:\n\nsalmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.samples is identical to the metadata samples.txt file.\nsalmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.P0.001_C2.dark-UP.subset is the subset of expression matrix of up-regulated transcripts in Dark group, which are down-regulated in Normal light group.\nsalmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.P0.001_C2.normal_light-UP.subset is the subset of expression matrix of up-regulated transcripts in Normal light group, which are down-regulated in Dark group.\nsalmon.isoform.counts.matrix.dark_vs_normal_light.DESeq2.DE_results.P0.001_C2.DE.subset is a summary of DE transcripts results containing columns of significant values, and its normalized expression value.\ndiffExpr.P0.001_C2.matrix.log2.centered.sample_cor_matrix.pdf is the sample correlation matrix, as follow.\n\n\n\n\nSample correlation matrix visualized only for differentially expressed transcripts.\n\n\n\ndiffExpr.P0.001_C2.matrix.log2.centered.genes_vs_samples_heatmap.pdf is heatmap of differentially expressed transcripts.\n\n\n\n\nHeatmap of differentially expressed transcripts."
  },
  {
    "objectID": "06_de_analysis.html#de-gene-patterning-and-clustering-analysis",
    "href": "06_de_analysis.html#de-gene-patterning-and-clustering-analysis",
    "title": "6¬† Estimating Abundance and Differential Expression Analysis of Genes",
    "section": "6.6 DE gene patterning and clustering analysis",
    "text": "6.6 DE gene patterning and clustering analysis\nIn the heat map of differentially expressed transcripts, there is a clear difference between the DE transcripts under dark and normal light conditions. Therefore, using define_clusters_by_cutting_tree.pl, we can divide these genes into clusters based on the same trend of expression values as follows.\n\n\n\n\n\n\nActivity\n\n\n\nAutomatically Partitioning Genes into Expression Clusters\ndefine_clusters_by_cutting_tree.pl \\\n-R diffExpr.P0.001_C2.matrix.RData \\\n--Ptree 60\n\n\nThere are three different methods for dividing genes into clusters, K-Means clustering, hierarchical clustering (as used in the heatmap), and the recommended method of using criteria to truncate tree branch lengths that fall below the criteria by using ‚Äò‚ÄìPtree‚Äô.\nThe following results will append to the current working directory DESeq2_result which are files and diffExpr.P0.001_C2.matrix.RData.clusters_fixed_P_60/ directory.\n-rw-rw---- 1 root PSLab    45837 Mar  6 16:51 clusters_fixed_P_60.heatmap.heatmap_gene_order.txt\n-rw-rw---- 1 root PSLab    61467 Mar  6 16:51 clusters_fixed_P_60.heatmap.gene_cluster_colors.dat\n-rw-rw---- 1 root PSLab   110890 Mar  6 16:51 clusters_fixed_P_60.heatmap.heatmap.pdf\ndrwxrwx--- 1 root PSLab      400 Mar  6 16:51 diffExpr.P0.001_C2.matrix.RData.clusters_fixed_P_60/\nList of files in diffExpr.P0.001_C2.matrix.RData.clusters_fixed_P_60/ directory are:\n-rw-rw---- 1 root PSLab  43915 Mar  6 16:51 my_cluster_plots.pdf\n-rw-rw---- 1 root PSLab 220780 Mar  6 16:51 subcluster_1_log2_medianCentered_fpkm.matrix\n-rw-rw---- 1 root PSLab  26259 Mar  6 16:51 subcluster_2_log2_medianCentered_fpkm.matrix\n-rw-rw---- 1 root PSLab    816 Mar  6 16:51 __tmp_plot_clusters.R\nThe DE transcript partiitoning and clustering is located in my_cluster_plots.pdf\n\n\n\nDE transcript partiitoning and clustering analysis"
  }
]